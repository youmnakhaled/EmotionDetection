{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from skimage.feature import canny\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC #, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(image):   \n",
    "    image = cv2.resize(image,(500,500))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return gray,image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viola**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********start of code**********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    rects=[]\n",
    "    count_rects=0\n",
    "    threshold=None\n",
    "    left_leaf_value=None\n",
    "    right_leaf_value=None\n",
    "    left_node=None\n",
    "    right_node=None\n",
    "    found_left_leaf=None\n",
    "    found_right_leaf=None\n",
    "    width=None\n",
    "    height=None\n",
    "    \n",
    "    def __init__(self,threshold,left_leaf_value,right_leaf_value,left_node,right_node,found_left_leaf,found_right_leaf,width\n",
    "    ,height):\n",
    "        self.threshold=threshold\n",
    "        self.left_leaf_value=left_leaf_value\n",
    "        self.right_leaf_value=right_leaf_value\n",
    "        self.left_node=left_node\n",
    "        self.right_node=right_node\n",
    "        self.found_left_leaf=found_left_leaf\n",
    "        self.found_right_leaf=found_right_leaf\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.rects=[]\n",
    "        self.count_rects=0\n",
    "        \n",
    "    def add_rectangle(self,x1,x2,y1,y2,weight):\n",
    "        self.rects.append([float(x1),float(x2),float(y1),float(y2),float(weight)])\n",
    "        self.count_rects+=1\n",
    "        \n",
    "    def get_direction(self,integral_image,squared_integral,i,j,scale_window,inv_no_pixels,variance):     \n",
    "        sum_rectangles = 0\n",
    "        for rect in self.rects:\n",
    "            rx1=i + int(scale_window*rect[0])\n",
    "            rx2=i + int(scale_window*(rect[0]+rect[2]))\n",
    "            ry1=j + int(scale_window*rect[1])\n",
    "            ry2=j + int(scale_window*(rect[1]+rect[3]))\n",
    "            \n",
    "            sum_rectangles += int((integral_image[rx2][ry2]-integral_image[rx1][ry2]-integral_image[rx2][ry1]+integral_image[rx1][ry1])*rect[4]);          \n",
    "        mean_rectangles = sum_rectangles*inv_no_pixels\n",
    "        return mean_rectangles<(self.threshold*variance) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    features=[]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.features=[]\n",
    "        \n",
    "    def add_feature(self,feature):\n",
    "        self.features.append(feature)\n",
    "        \n",
    "    def get_feature_value(self,integral_image,squared_integral,i,j,scale_window,inv_no_pixels,variance):\n",
    "        node = self.features[0]\n",
    "        if(node.get_direction(integral_image,squared_integral,i,j,scale_window,inv_no_pixels,variance)):\n",
    "            if(node.found_left_leaf):\n",
    "                return node.left_leaf_value\n",
    "            else:\n",
    "                node = self.features[node.left_node]\n",
    "        else:\n",
    "            if(node.found_right_leaf):\n",
    "                return node.right_leaf_value\n",
    "            else:\n",
    "                node = self.features[node.right_node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage:\n",
    "    trees=[]\n",
    "    threshold=None\n",
    "    \n",
    "    def __init__(self,threshold):\n",
    "        self.threshold=threshold\n",
    "        self.trees=[]\n",
    "\n",
    "    def add_tree(self,tree):\n",
    "        self.trees.append(tree)\n",
    "        \n",
    "    def pass_stage(self,integral_image,squared_integral,i,j,scale_window,inv_no_pixels,variance):\n",
    "        sum_trees = 0\n",
    "        for tree in self.trees:\n",
    "            sum_trees += tree.get_feature_value(integral_image,squared_integral,i,j,scale_window,inv_no_pixels,variance)\n",
    "        return sum_trees > self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Viola:\n",
    "    width=None\n",
    "    height=None\n",
    "    stages=[]\n",
    "    \n",
    "    def read_xml(self):\n",
    "        with open('haarcascade_frontalface_default.xml', 'r', encoding='utf-8') as file:\n",
    "            my_xml = file.read()\n",
    "        my_dict = xmltodict.parse(my_xml)\n",
    "        \n",
    "        self.height= int(my_dict['opencv_storage']['cascade']['height'])\n",
    "        self.width= int(my_dict['opencv_storage']['cascade']['width'])\n",
    "        stageNum=int(my_dict['opencv_storage']['cascade']['stageNum'])\n",
    "        \n",
    "        for stage_i in range(stageNum):\n",
    "            maxWeakCount=int(my_dict['opencv_storage']['cascade']['stages']['_'][stage_i]['maxWeakCount'])\n",
    "            stageThreshold=float(my_dict['opencv_storage']['cascade']['stages']['_'][stage_i]['stageThreshold'])\n",
    "            st= Stage(stageThreshold)\n",
    "            \n",
    "            stage= my_dict['opencv_storage']['cascade']['stages']['_'][stage_i]\n",
    "            for tree_i in range(maxWeakCount):\n",
    "                t = Tree()\n",
    "                internalNodes = stage['weakClassifiers']['_'][tree_i]['internalNodes']\n",
    "                leafValues = stage['weakClassifiers']['_'][tree_i]['leafValues']\n",
    "                \n",
    "                internalNodes = internalNodes.split(\" \")\n",
    "                threshold = float(internalNodes[3])\n",
    "                feature_index = int(internalNodes[2])\n",
    "\n",
    "                leafValues = leafValues.split(\" \")\n",
    "                left_leaf_value = float(leafValues[0])\n",
    "                right_leaf_value = float(leafValues[1])\n",
    "\n",
    "                f=Feature(threshold,left_leaf_value,right_leaf_value,-1,-1,True,True,self.width,self.height)\n",
    "\n",
    "                rects= my_dict['opencv_storage']['cascade']['features']['_'][feature_index]['rects']['_']\n",
    "                for rect_i in rects:\n",
    "                    rect_i= rect_i.split(\" \")\n",
    "                    f.add_rectangle(*rect_i)\n",
    "                \n",
    "                t.add_feature(f) \n",
    "                st.add_tree(t)\n",
    "                \n",
    "            self.stages.append(st)\n",
    "            \n",
    "    def detect_faces(self,image,base_scale,inc_scale,inc_sliding,min_neighbours,do_canny_pruning,org,k):\n",
    "        original = np.copy(image)\n",
    "        image = np.swapaxes(image,0,1)\n",
    "        # image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        rects = []\n",
    "        img_width = image.shape[0]\n",
    "        img_height = image.shape[1]\n",
    "        max_scale = min((img_width/self.width),(img_height/self.height))\n",
    "        \n",
    "#         Handmade Integral:\n",
    "#         integral_image = np.zeros((img_width,img_height))\n",
    "#         squared_integral = np.zeros((img_width,img_height))  \n",
    "#         for i in range(img_width):\n",
    "#             sum_curr_row=0\n",
    "#             sum_curr_row2=0\n",
    "#             for j in range(img_height):\n",
    "#                 curr_pixel = image[i][j]\n",
    "#                 if (i==0):\n",
    "#                     integral_image[i][j] = sum_curr_row+curr_pixel\n",
    "#                     squared_integral[i][j] = sum_curr_row2+curr_pixel*curr_pixel\n",
    "#                 else:\n",
    "#                     integral_image[i][j] = sum_curr_row+curr_pixel+integral_image[i-1][j]\n",
    "#                     squared_integral[i][j] = sum_curr_row2+curr_pixel*curr_pixel+squared_integral[i-1][j]\n",
    "                    \n",
    "#                 sum_curr_row+=curr_pixel;\n",
    "#                 sum_curr_row2+=curr_pixel*curr_pixel;\n",
    "\n",
    "        integral_image, squared_integral = cv2.integral2(image)\n",
    "#         integral_image= integral_image[1:,1:,]\n",
    "#         squared_integral = squared_integral[1:,1:,]\n",
    "        \n",
    "        if (do_canny_pruning):\n",
    "            canny_image = canny(image, sigma=4).astype('uint8')*255\n",
    "            integral_canny, squared_canny = cv2.integral2(canny_image)\n",
    "#             integral_canny = integral_canny[1:,1:,]\n",
    "            \n",
    "            \n",
    "        scale = 1.0\n",
    "        for scale in np.arange(base_scale,max_scale,scale*inc_scale):\n",
    "            step = int(scale*self.width*inc_sliding)\n",
    "            size = int(scale*self.width)\n",
    "            inv_no_pixels = 1/(size*size)\n",
    "            for i in np.arange(0,img_width-size,step):               \n",
    "                for j in np.arange(0,img_height-size,step):\n",
    "                    if (do_canny_pruning):\n",
    "                        edges_density = integral_canny[i+size][j+size]+integral_canny[i][j]-integral_canny[i][j+size]-integral_canny[i+size][j]\n",
    "                        d = edges_density/(size*size)\n",
    "#                         Canny sigma 1\n",
    "#                         if(d<4 or d>10):\n",
    "#                             continue\n",
    "#                       Canny sigma 4\n",
    "                        if(d<0.2 or d>10):  #0.5,4\n",
    "                            continue\n",
    "                    \n",
    "                    face_detected = True                  \n",
    "                    sum_window=integral_image[i+size][j+size]+integral_image[i][j]-integral_image[i][j+size]-integral_image[i+size][j]\n",
    "                    sum_window2=squared_integral[i+size][j+size]+squared_integral[i][j]-squared_integral[i][j+size]-squared_integral[i+size][j]\n",
    "                    mean = sum_window*inv_no_pixels\n",
    "                    variance = sum_window2*inv_no_pixels-(mean*mean)\n",
    "                    if (variance>1):\n",
    "                        variance = math.sqrt(variance)\n",
    "                    else:\n",
    "                        variance = 1\n",
    "                        \n",
    "                    for stage in self.stages:\n",
    "                        if(stage.pass_stage(integral_image,squared_integral,i,j,scale,inv_no_pixels,variance)==False):\n",
    "                            face_detected = False\n",
    "                            break\n",
    "                    if(face_detected):\n",
    "                        rects.append([j,i,size,size])\n",
    "                        # print(\"Face detected\")\n",
    "#                         print(i,j,size,d)\n",
    "\n",
    "        merged_rects,_ = cv2.groupRectangles(np.asarray(rects).tolist(), min_neighbours, 0.2)\n",
    "        # print(len(rects))\n",
    "        print(\"FD\",len(merged_rects))\n",
    "        cropped_imgs = []\n",
    "        org_imgs = []\n",
    "        columns =[]\n",
    "        rows=[]\n",
    "        widths=[]\n",
    "        if len(merged_rects)!=0:\n",
    "            for rect in merged_rects:\n",
    "                original = cv2.rectangle(\n",
    "                    original,\n",
    "                    (rect[1], rect[0]),\n",
    "                    (rect[1] + rect[2], rect[0] + rect[2]),\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "                x=rect[0]\n",
    "                y=rect[1]\n",
    "                w=rect[2]\n",
    "\n",
    "    #             cropped_img=original[(rect[0]+50):(rect[0]+rect[2]-50),(rect[1]+70):(rect[1]+rect[2]-70)]\n",
    "    #             cropped_img=original[(rect[0]):(rect[0]+rect[2]),(rect[1]+60):(rect[1]+rect[2]-60)]\n",
    "\n",
    "    #             cropped_img=original[(rect[0]):(rect[0]+rect[2]),(rect[1]):(rect[1]+rect[2])]\n",
    "                cropped_img=original[(rect[0]+40):(rect[0]+rect[2]-20),(rect[1]+40):(rect[1]+rect[2]-45)]\n",
    "                if k!=-1:\n",
    "                    cv2.imwrite('afterViola500\\\\'+str(k)+'.jpg',cropped_img)\n",
    "\n",
    "    #             cropped_img= cv2.resize(cropped_img,(500,500))\n",
    "                cropped_img= cv2.resize(cropped_img,(48,64))\n",
    "\n",
    "                org=org[(rect[0]+40):(rect[0]+rect[2]-20),(rect[1]+40):(rect[1]+rect[2]-45),:]\n",
    "                if k!=-1:\n",
    "                    cv2.imwrite('afterViola500Color\\\\'+str(k)+'.jpg',org)\n",
    "\n",
    "    #             org= imutils.resize(org, width = 500,height = 500)\n",
    "                org= imutils.resize(org, width = 48,height = 64)\n",
    "\n",
    "                cropped_imgs.append(cropped_img)\n",
    "                org_imgs.append(org)\n",
    "                columns.append(x)\n",
    "                rows.append(y)\n",
    "                widths.append(w)\n",
    "            # show_images([original])\n",
    "            # show_images([cropped_img])\n",
    "\n",
    "        else:\n",
    "            return cropped_imgs ,org_imgs,0,0,0\n",
    "        \n",
    "        return cropped_imgs ,org_imgs,columns,rows,widths\n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viola(gray,viola,org,k):\n",
    "    return viola.detect_faces(gray,5,1.25,0.1,1,True,org,k)\n",
    "#     10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********End of Code**********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CV- Viola**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viola1(gray):\n",
    "    detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    rects = detector.detectMultiScale(gray,scaleFactor=1.1,\n",
    "                                        minNeighbors=5,\n",
    "                                        minSize=(30, 30),\n",
    "                                        flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "\n",
    "    # print(\"rects:\",len(rects))\n",
    "    optional2=0\n",
    "    cropped_imgs = []\n",
    "    org_imgs = []\n",
    "    columns =[]\n",
    "    rows=[]\n",
    "    widths=[]\n",
    "    if (len(rects)!= 0):\n",
    "        for (column, row, width, height) in rects:\n",
    "            cv2.rectangle(\n",
    "                gray,\n",
    "                (column, row),\n",
    "                (column + width, row + height),\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "            # show_images([gray[row:row+width,column:column+height]])\n",
    "\n",
    "            optional=gray[(row):(row+width),(column):(column+height)]\n",
    "            optional2= cv2.resize(optional,(60,80))\n",
    "            cropped_imgs.append(optional2)\n",
    "            columns.append(column)\n",
    "            rows.append(row)\n",
    "            widths.append(width)\n",
    "    else:\n",
    "        return cropped_imgs,0,0,0\n",
    "\n",
    "    return cropped_imgs,columns,rows,widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        plt.axis('off')\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions for Dlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first utility function is rect_to_bb , short for “rectangle to bounding box”:\n",
    "def rect_to_bb(rect):\n",
    "\t# take a bounding predicted by dlib and convert it\n",
    "\t# to the format (x, y, w, h) as we would normally do\n",
    "\t# with OpenCV\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    "\t# return a tuple of (x, y, w, h)\n",
    "\treturn (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\t# initialize the list of (x, y)-coordinates\n",
    "\tcoords = np.zeros((68, 2), dtype=dtype)\n",
    "\t# loop over the 68 facial landmarks and convert them\n",
    "\t# to a 2-tuple of (x, y)-coordinates\n",
    "\tfor i in range(0, 68):\n",
    "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\t# return the list of (x, y)-coordinates\n",
    "\treturn coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dlib_func(gray):\n",
    "    # initialize dlib's face detector (HOG-based) and then create\n",
    "    # the facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 1)\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "        # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(gray, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # show the face number\n",
    "        cv2.putText(gray, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the image\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(gray, (x, y), 1, (0, 0, 255), -1)\n",
    "    # show_images([gray])\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Models***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(training_features, y_train):\n",
    "#     lab_enc = preprocessing.LabelEncoder()\n",
    "#     training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "#     clf = LinearSVC(C=1, max_iter=8000)  #SVC(kernel='linear',c=1,)\n",
    "#     clf = SVC(kernel='poly',C=1,gamma=\"scale\")\n",
    "    clf = SVC(kernel='linear',C=5,gamma=\"scale\")\n",
    "#     clf = SVC(kernel='rbf',C=4,gamma=\"scale\")\n",
    "    clf.fit(training_features, y_train)  \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, y_train):\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "    classifier = KNeighborsClassifier(n_neighbors=3) \n",
    "    classifier.fit(X_train, training_scores_encoded)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randome_Forest(X_train, y_train):\n",
    "    clf_Randome_Forest = RandomForestClassifier(n_estimators=800)\n",
    "    clf_Randome_Forest.fit(X_train, y_train)\n",
    "    return clf_Randome_Forest\n",
    "\n",
    "# clf_Randome_Forest = pickle.load(open('random_forest.sav', 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(X_train, y_train):\n",
    "    clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential  \n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten  \n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D  \n",
    "# from keras.losses import categorical_crossentropy  \n",
    "# from keras.optimizers import Adam  \n",
    "# from keras.regularizers import l2  \n",
    "# from keras.utils import np_utils  \n",
    "\n",
    "# def NeuralNetwork(X_train, train_y):\n",
    "#     num_features = 64  \n",
    "#     num_labels = 7  \n",
    "#     batch_size = 64  \n",
    "#     epochs = 30  \n",
    "#     width, height = 48, 48 \n",
    "    \n",
    "#     model = Sequential()  \n",
    "#     model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))  \n",
    "#     model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))  \n",
    "#     # model.add(BatchNormalization())  \n",
    "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
    "#     model.add(Dropout(0.5))  \n",
    "\n",
    "#     #2nd convolution layer  \n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))  \n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))  \n",
    "#     # model.add(BatchNormalization())  \n",
    "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
    "#     model.add(Dropout(0.5))  \n",
    "\n",
    "#     #3rd convolution layer  \n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu'))  \n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu'))  \n",
    "#     # model.add(BatchNormalization())  \n",
    "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n",
    "\n",
    "#     model.add(Flatten())  \n",
    "\n",
    "#     #fully connected neural networks  \n",
    "#     model.add(Dense(1024, activation='relu'))  \n",
    "#     model.add(Dropout(0.2))  \n",
    "#     model.add(Dense(1024, activation='relu'))  \n",
    "#     model.add(Dropout(0.2))  \n",
    "\n",
    "#     model.add(Dense(num_labels, activation='softmax'))  \n",
    "\n",
    "#     # model.summary()  \n",
    "\n",
    "#     #Compliling the model  \n",
    "#     model.compile(loss=categorical_crossentropy,  \n",
    "#                   optimizer=Adam(),  \n",
    "#                   metrics=['accuracy'])  \n",
    "\n",
    "#     #Training the model  \n",
    "#     model.fit(X_train, train_y,  \n",
    "#               batch_size=batch_size,  \n",
    "#               epochs=epochs,  \n",
    "#               verbose=1,  \n",
    "#               validation_data=(X_test, test_y),  \n",
    "#               shuffle=True)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_original = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_paths_to_files(dataset_dir):\n",
    "    labels_train=[]\n",
    "    images_train=[]\n",
    "    labels_test=[]\n",
    "    images_test=[]\n",
    "    emotion_dict={\n",
    "        \"anger\":0,\n",
    "        \"disgust\":1,\n",
    "        \"fear\":2,\n",
    "        \"happiness\":3,\n",
    "        \"neutral\":4,\n",
    "        \"sadness\":5,\n",
    "        # \"surprise\":6\n",
    "    }\n",
    "    # emotion_dict={\n",
    "    #     \"anger\":0,\n",
    "    #     \"disgust\":0,\n",
    "    #     \"fear\":0,\n",
    "    #     \"happiness\":1,\n",
    "    #     \"neutral\":1,\n",
    "    #     \"sadness\":1,\n",
    "    #     # \"surprise\":6\n",
    "    # }\n",
    "    # emotion_dict={\n",
    "    #     \"anger\":0,\n",
    "    #     \"disgust\":0,\n",
    "    #     \"fear\":0,\n",
    "    #     \"happiness\":1,\n",
    "    #     \"neutral\":1,\n",
    "    #     \"sadness\":1,\n",
    "    #     # \"surprise\":6\n",
    "    # }\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    folders_1 = sorted(glob.glob (str(dataset_dir)+\"/*\"))\n",
    "    # print(\"1\",folders_1)\n",
    "    fold_num=0\n",
    "    num_train = 0\n",
    "    num_test = 0\n",
    "    for folder3 in folders_1:\n",
    "        # print(folder3)\n",
    "        # for folder2 in folder3:\n",
    "            # print(folder2)\n",
    "        # for folder2 in folders_1:\n",
    "        fold_num+=1\n",
    "        emotions = sorted(glob.glob(str(folder3)+\"\\\\\"+str(folder3).split(\"\\\\\")[-1]+ \"/*\"))\n",
    "        # print(\"emotion\",emotions)\n",
    "        for emotion in emotions:\n",
    "            dir = emotion.split('\\\\')\n",
    "            e= dir[-1]\n",
    "            # print(\"e\",e)\n",
    "            if e != 'mixed' and e != 'extra' and e!='surprise' and e!='neutral':\n",
    "                if os.path.isdir(emotion):\n",
    "                    takes = sorted(glob.glob (emotion+'/*'))\n",
    "                    # print(\"youmna\",takes)\n",
    "                    for take in takes:\n",
    "                        curr = sorted(glob.glob (take+'/*.jpg'))\n",
    "                        i=0\n",
    "                        # print(\"fo2 image\")\n",
    "                        for image in curr:\n",
    "                            # if read_original==0:\n",
    "                            #     curr = sorted(glob.glob (take+'/*.jpg'))\n",
    "                            #     for image in curr: \n",
    "                            #         img = cv2.imread(r'trainingSet\\\\'+e+'\\\\take000\\\\'+str(num_train)+'.jpg')\n",
    "                            #         images_test.append(img)\n",
    "                            #         labels_test.append(emotion_dict[e])\n",
    "                                    \n",
    "                            if i>int(len(curr)/2) and i<=int((len(curr)/2)+1):\n",
    "                                # print(\"ta7t if\")\n",
    "                                if fold_num<45:\n",
    "#                                 if fold_num==1:\n",
    "                                    if read_original == 0:\n",
    "                                        # print(\"sdhnmkjf\")\n",
    "                                        img = cv2.imread(image) \n",
    "                                        cv2.imwrite('trainingSet\\\\'+e+'\\\\take000\\\\'+str(num_train)+'.jpg',img)\n",
    "                                    else:\n",
    "                                        # print(\"elsee fo2\")\n",
    "                                        img = cv2.imread(r'trainingSet\\\\'+e+'\\\\take000\\\\'+str(num_train)+'.jpg')\n",
    "                                        show_images([img])\n",
    "                                    num_train+=1\n",
    "                                    images_train.append(img)\n",
    "                                    labels_train.append(emotion_dict[e])\n",
    "                                else:\n",
    "                                    # print(\"elsee ta7t\")\n",
    "                                    if read_original == 0:\n",
    "                                        img = cv2.imread(image) \n",
    "                                        cv2.imwrite('testSet\\\\'+e+'\\\\take000\\\\'+str(num_test)+'.jpg',img)\n",
    "                                    else:\n",
    "                                        img = cv2.imread(r'testSet\\\\'+e+'\\\\take000\\\\'+str(num_test)+'.jpg')\n",
    "                                    images_test.append(img)\n",
    "                                    labels_test.append(emotion_dict[e])\n",
    "                                    num_test+=1\n",
    "                            i=i+1\n",
    "\n",
    "    return labels_train,images_train,labels_test,images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stored_imgs():\n",
    "    labels_train=[]\n",
    "    images_train=[]\n",
    "    labels_test=[]\n",
    "    images_test=[]\n",
    "    emotion_dict={\n",
    "        \"anger\":0,\n",
    "        \"disgust\":1,\n",
    "        \"fear\":2,\n",
    "        \"happiness\":3,\n",
    "        \"neutral\":4,\n",
    "        \"sadness\":5,\n",
    "        # \"surprise\":6\n",
    "    }\n",
    "    # emotion_dict={\n",
    "    #     \"anger\":0,\n",
    "    #     \"disgust\":0,\n",
    "    #     \"fear\":0,\n",
    "    #     \"happiness\":1,\n",
    "    #     \"neutral\":1,\n",
    "    #     \"sadness\":1,\n",
    "    #     # \"surprise\":6\n",
    "    # }\n",
    "\n",
    "    # emotion_dict={\n",
    "    #     \"anger\":0,\n",
    "    #     \"disgust\":0,\n",
    "    #     \"fear\":0,\n",
    "    #     \"happiness\":1,\n",
    "    #     \"neutral\":1,\n",
    "    #     \"sadness\":1,\n",
    "    #     # \"surprise\":6\n",
    "    # }\n",
    "    path_of_the_directory=\"C:\\\\Users\\\\farah\\\\Desktop\\\\Image project\\\\trainingSet\"\n",
    "    # path_of_the_directory=\"C:\\\\Users\\\\farah\\\\Desktop\\\\Image project\\\\trainingSet\"\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        emotions = os.path.join(path_of_the_directory,filename)\n",
    "        # print(emotions)\n",
    "        path=emotions+'\\\\take000\\\\'\n",
    "        for images in os.listdir(path):\n",
    "            image = os.path.join(path,images)\n",
    "            img = cv2.imread(image)\n",
    "            # show_images([img])\n",
    "            images_train.append(img)\n",
    "            labels_train.append(emotion_dict[filename])\n",
    "\n",
    "    path_of_the_directory=\"C:\\\\Users\\\\farah\\\\Desktop\\\\Image project\\\\testSet\"\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        emotions = os.path.join(path_of_the_directory,filename)\n",
    "        # print(emotions)\n",
    "        path=emotions+'\\\\take000\\\\'\n",
    "        for images in os.listdir(path):\n",
    "            image = os.path.join(path,images)\n",
    "            img = cv2.imread(image)\n",
    "            # show_images([img])\n",
    "            images_test.append(img)\n",
    "            labels_test.append(emotion_dict[filename])\n",
    "    return labels_train,images_train,labels_test,images_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (read_original==0):\n",
    "    labels_train,images_train,labels_test,images_test=collect_paths_to_files(\"Y:\\\\GP\\\\MUG\\\\subjects3\")\n",
    "    # labels_train,images_train,labels_test,images_test=collect_paths_to_files(\"C:\\\\Users\\\\farah\\\\Desktop\\\\Image project\\\\temp\")\n",
    "else:\n",
    "    labels_train,images_train,labels_test,images_test=read_stored_imgs()\n",
    "    \n",
    "# labels_train,images_train,labels_test,images_test=collect_paths_to_files(\"C:\\\\Users\\\\PC\\\\Desktop\\\\Semester 9\\\\Image\\\\Project\\\\sowar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test 108\n",
      "size of train 600\n"
     ]
    }
   ],
   "source": [
    "print(\"size of test\",len(labels_test))\n",
    "print(\"size of train\",len(labels_train))\n",
    "labels_dataset = copy.deepcopy(labels_train)\n",
    "images_dataset = copy.deepcopy(images_train)\n",
    "for i in range (len(labels_test)):\n",
    "    labels_dataset.append(labels_test[i])\n",
    "    images_dataset.append(images_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels_test)):\n",
    "    # image=cv2.imread(os.path.join(DIR, i))\n",
    "    # blurred_image = motion_blur(image)\n",
    "    cv2.imwrite('Y:/GP/labelTest/'+str(labels_test[i])+'_'+str(i)+'.png',images_test[i]) \n",
    "    # count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labelTest.txt', 'w') as file:\n",
    "    for label in labels_test:\n",
    "        file.write(\"%i\\n\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gabor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaborFun(image):\n",
    "    features = []\n",
    "    sizes=[5,9,11,15,19]\n",
    "    phi=0\n",
    "    gamma = 0.5\n",
    "    sigma = 5\n",
    "    lam = np.pi/4.\n",
    "    for theta in range (8): #8\n",
    "        theta=theta/4.*np.pi\n",
    "        for i in range (len(sizes)):\n",
    "            kernel=cv2.getGaborKernel((sizes[i], sizes[i]), sigma, theta, lam, gamma, phi, ktype=cv2.CV_32F)\n",
    "            fimg = cv2.filter2D(image, cv2.CV_8UC3, kernel)    \n",
    "            filteredImage=fimg.reshape(-1)\n",
    "            features.append(filteredImage)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eigen Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenFun(X_train):\n",
    "    # images_grayscale=[]\n",
    "    # for i in range(len(X_train)):\n",
    "    #     # image_gray = color.rgb2gray(X_train[i])\n",
    "    #     image_gray = X_train[i].flatten()\n",
    "    #     # print(image_gray.shape)\n",
    "    #     # image_gray=image_gray.reshape(image_gray.shape[0],1)\n",
    "    #     # print(image_gray)\n",
    "    #     images_grayscale.append(image_gray)\n",
    "    # print(images_grayscale[0].shape)\n",
    "    # plt.figure(figsize=(18, 7))\n",
    "    # print(\"list el gray scale\",len(images_grayscale))\n",
    "    # print(\"shape el image el wa7da\",images_grayscale[0].shape)\n",
    "    # images_grayscale=np.array(images_grayscale)\n",
    "    # print(\"shape el image \",images_grayscale.shape)\n",
    "    # pca = PCA().fit(X_train)\n",
    "    # plt.plot(pca.explained_variance_ratio_.cumsum(), lw=3)\n",
    "    # print((np.where(pca.explained_variance_ratio_.cumsum() > 0.95)))\n",
    "\n",
    "    # pca = PCA(n_components=(np.where(pca.explained_variance_ratio_.cumsum() > 0.80))[0][0]).fit(X_train)\n",
    "    pca = PCA(n_components=90).fit(X_train)\n",
    "    \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenFunGabor(X_train):\n",
    "    # images_grayscale=[]\n",
    "    # for i in range(len(X_train)):\n",
    "    #     # image_gray = color.rgb2gray(X_train[i])\n",
    "    #     image_gray = X_train[i].flatten()\n",
    "    #     # print(image_gray.shape)\n",
    "    #     # image_gray=image_gray.reshape(image_gray.shape[0],1)\n",
    "    #     # print(image_gray)\n",
    "    #     images_grayscale.append(image_gray)\n",
    "    # print(images_grayscale[0].shape)\n",
    "    # plt.figure(figsize=(18, 7))\n",
    "    # print(\"list el gray scale\",len(images_grayscale))\n",
    "    # print(\"shape el image el wa7da\",images_grayscale[0].shape)\n",
    "    # images_grayscale=np.array(images_grayscale)\n",
    "    # print(\"shape el image \",images_grayscale.shape)\n",
    "    # pca = PCA().fit(X_train)\n",
    "    # plt.plot(pca.explained_variance_ratio_.cumsum(), lw=3)\n",
    "    # print((np.where(pca.explained_variance_ratio_.cumsum() > 0.95)))\n",
    "\n",
    "    # pca = PCA(n_components=(np.where(pca.explained_variance_ratio_.cumsum() > 0.97))[0][0]).fit(X_train)\n",
    "    pca = PCA(n_components=270).fit(X_train)\n",
    "    \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra trials for Eigen Faces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_faces(train):\n",
    "    images_grayscale=[]\n",
    "    for i in range(len(train)):\n",
    "        image_gray = color.rgb2gray(train[i])\n",
    "        image_gray = image_gray.reshape(-1)\n",
    "        images_grayscale.append(image_gray)\n",
    "#########################PCA\n",
    "    M=len(images_grayscale)\n",
    "    print(\"length of images\",M)\n",
    "    mean_of_training_set = np.mean(images_grayscale, axis=0)\n",
    "    print(\"mean.shape\",mean_of_training_set.shape)\n",
    "    subtracted_list = []\n",
    "    for i in range (M):\n",
    "        x=images_grayscale[i]-mean_of_training_set #Subtract the calculated mean from the vector of training image to find subtracted mean\n",
    "        subtracted_list.append(x) #Indicates the difference between the vector of m’th training image and the mean image.\n",
    "    sigma = (np.var(images_grayscale, axis=0))**0.5\n",
    "    normalized_X = (images_grayscale-mean_of_training_set)/sigma\n",
    "    print(\"normaalized\", normalized_X.shape)\n",
    "    subtracted=np.array(subtracted_list).T\n",
    "    print(\"subtracted_list\",len(subtracted_list))   \n",
    "    print(\"subtracted_list\",subtracted_list[0].shape)   \n",
    "    print(\"subtracted\",subtracted.shape) #(8,313600)        \n",
    "    subtracted_transpose=subtracted.T\n",
    "    print(\"subtracted_transpose\",subtracted_transpose.shape)\n",
    "    print(\"normaalized\", normalized_X)\n",
    "    print(\"subtracted\",subtracted_transpose)  \n",
    "    covariance=np.dot(normalized_X,normalized_X.T)/(normalized_X.T).shape[0]\n",
    "    # covariance=np.dot(subtracted_transpose,subtracted)/(subtracted).shape[0]\n",
    "    # cov = np.dot(X.T, X)/X.shape[0]\n",
    "    # _, eigenvalues, eigenvectors = np.linalg.svd(covariance, full_matrices=False)\n",
    "\n",
    "    # C = np.dot(subtracted,eigenvectors[1])\n",
    "    # C1=np.dot(subtracted_transpose,C)\n",
    "    # lam = np.dot(eigenvalues[1],eigenvectors[1])\n",
    "    # return covariance, eigenvalues, eigenvectors, C1, lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "read=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_training(trainX,labelsX,viola_inst):\n",
    "    features = []\n",
    "    mxm = len(labelsX)\n",
    "    trainAfterPreProcess=[]\n",
    "    labelsOut=[]\n",
    "    for i in range(mxm):\n",
    "        # print(i)\n",
    "        image = trainX[i]\n",
    "        if(read==0):  \n",
    "            gray_out,image_out1=Preprocess(image)\n",
    "            # gray_out2,image_out2,_,_,_=viola(gray_out,viola_inst,image_out1,i)\n",
    "            gray_out2,x,y,w=viola1(gray_out)\n",
    "            if (len(gray_out2)!=0):\n",
    "                cv2.imwrite('afterViola\\\\'+str(i)+'.jpg',gray_out2[0])\n",
    "                # cv2.imwrite('afterViolaOrg\\\\'+str(i)+'.jpg',image_out2[0])\n",
    "                \n",
    "        else:\n",
    "            gray_out2 = [cv2.imread(r'afterViolaKFold\\\\'+str(i)+'.jpg',cv2.IMREAD_GRAYSCALE)]\n",
    "            # image_out2 = [cv2.imread(r'afterViolaOrg\\\\'+str(i)+'.jpg')]\n",
    "        if (len(gray_out2)!=0):\n",
    "            image_out3 = gray_out2[0]\n",
    "            flattend_image=image_out3.flatten()\n",
    "            trainAfterPreProcess.append(flattend_image)\n",
    "            curr=gaborFun(image_out3)\n",
    "            curr=np.array(curr)\n",
    "            curr=curr.flatten()   \n",
    "            features.append(curr)\n",
    "            # print(\"curr shape=\",curr.shape)\n",
    "            labelsOut.append(labelsX[i])\n",
    "\n",
    "    features= np.array(features)  \n",
    "    pca=eigenFun(trainAfterPreProcess)#(8,5)\n",
    "    X_train_pca = pca.transform(trainAfterPreProcess)\n",
    "    # X_train_pca = trainAfterPreProcess\n",
    "    print(\"X_train_pca\",X_train_pca.shape) \n",
    "\n",
    "    \n",
    "    pcaGabor=eigenFunGabor(features)\n",
    "    gabor_pca = pcaGabor.transform(features)\n",
    "    # gabor_pca = features\n",
    "    print(\"gabor_pca\",gabor_pca.shape)  \n",
    "    f=np.append(gabor_pca,X_train_pca,axis=1)\n",
    "    print(\"f=\",f.shape) \n",
    "    return f, pca,pcaGabor,labelsOut #pcaGabor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_test=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_test(test, pca,pcaGabor,viola_inst,k):\n",
    "    features = []\n",
    "    f=[]\n",
    "    image = test\n",
    "    if(read_test==0):  \n",
    "        gray_out,image_out1=Preprocess(image)\n",
    "        # gray_out2,image_out2,x,y,w=viola(gray_out,viola_inst,image_out1,-1)\n",
    "        gray_out2,x,y,w=viola1(gray_out)\n",
    "        if(len(gray_out2)!=0):\n",
    "            if k!=-1:\n",
    "                cv2.imwrite('afterViolaTest\\\\'+str(k)+'.jpg',gray_out2[0])\n",
    "                # cv2.imwrite('afterViolaOrgTest\\\\'+str(k)+'.jpg',image_out2[0])\n",
    "                        \n",
    "    else:\n",
    "        gray_out2=[]\n",
    "        image_out2=[]\n",
    "        gray_out2.append(cv2.imread(r'afterViolaTest\\\\'+str(k)+'.jpg',cv2.IMREAD_GRAYSCALE))\n",
    "        # print(len(gray_out2))\n",
    "        # image_out2.append(cv2.imread(r'afterViolaOrgTest\\\\'+str(k)+'.jpg'))\n",
    "\n",
    "    testAfterPreProcess=[]\n",
    "    # print(len(gray_out2))\n",
    "    if(len(gray_out2)!=0):\n",
    "        for face in gray_out2:\n",
    "            # print(\"IN\")\n",
    "            # print(type(face))\n",
    "            image_out3 =np.array(face)\n",
    "            # print(image_out3.shape)\n",
    "            # print(type(image_out3))\n",
    "            flattend_image=image_out3.flatten()\n",
    "            # print(\"flattened\",flattend_image.shape)\n",
    "            testAfterPreProcess.append(flattend_image)\n",
    "            curr=gaborFun(image_out3)\n",
    "            curr=np.array(curr)\n",
    "            curr=curr.flatten()   \n",
    "            features.append(curr)\n",
    "            # print(curr.shape)\n",
    "        \n",
    "        features= np.array(features)  \n",
    "        # print(\"curr=\",curr.shape)\n",
    "        # print(\"features=\",features.shape)\n",
    "        X_test_pca = pca.transform(testAfterPreProcess)\n",
    "        # X_test_pca = testAfterPreProcess\n",
    "        print(\"X_test_pca=\",X_test_pca.shape)\n",
    "\n",
    "\n",
    "        gabor_pca_test = pcaGabor.transform(features)\n",
    "        # gabor_pca_test = features\n",
    "        # print(\"gabor_pca_test\",gabor_pca_test.shape) \n",
    "        f=np.append(gabor_pca_test,X_test_pca,axis=1)\n",
    "    \n",
    "        print(\"f=\",f.shape) \n",
    "    if (read_test==1):\n",
    "        return f,0,0,0\n",
    "    \n",
    "    return f,x,y,w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TRAINING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pca (600, 90)\n",
      "gabor_pca (600, 270)\n",
      "f= (600, 360)\n",
      "--- 92.98318409919739 seconds ---\n"
     ]
    }
   ],
   "source": [
    "viola_inst = Viola()\n",
    "viola_inst.read_xml()\n",
    "start_time = time.time()\n",
    "features,pca,pcaGabor,labels_train=extract_features_training(images_train,labels_train,viola_inst)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "clf=SVM(features,labels_train)\n",
    "# clf=KNN(features,labels_train)\n",
    "# clf=Randome_Forest(features,labels_train)\n",
    "# clf=MLP(features,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TESTING [Without Camera]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (2, 90)\n",
      "f= (2, 360)\n",
      "prediction=  [2 0]\n",
      "Actual=  0\n",
      "X_test_pca= (2, 90)\n",
      "f= (2, 360)\n",
      "prediction=  [0 0]\n",
      "Actual=  0\n",
      "X_test_pca= (2, 90)\n",
      "f= (2, 360)\n",
      "prediction=  [1 0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [0]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  0\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [1]\n",
      "Actual=  1\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  2\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [3]\n",
      "Actual=  3\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [5]\n",
      "Actual=  5\n",
      "X_test_pca= (1, 90)\n",
      "f= (1, 360)\n",
      "prediction=  [2]\n",
      "Actual=  5\n",
      "SVM Classifier Accuracy:  86.11111111111111 %\n"
     ]
    }
   ],
   "source": [
    "svm_predictions=[]\n",
    "k=0\n",
    "for img in images_test:\n",
    "    test_point,_,_,_=extract_features_test(img,pca,pcaGabor,viola_inst,k+len(labels_train))\n",
    "    if(len(test_point)!=0):\n",
    "        res=clf.predict(test_point)\n",
    "        print(\"prediction= \",res)\n",
    "        print(\"Actual= \",labels_test[k])\n",
    "        svm_predictions.append(res[0])\n",
    "        # show_images([img])\n",
    "    k+=1\n",
    "\n",
    "        \n",
    "# results_SVM = np.array([svm_predictions[0] == labels_test])  \n",
    "# accuracy_SVM= results_SVM[results_SVM==True].shape[0]/np.array(labels_test).shape[0]\n",
    "\n",
    "# print(svm_predictions)\n",
    "# print(labels_test)\n",
    "# print(results_SVM)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_SVM2 = accuracy_score(labels_test, svm_predictions)\n",
    "\n",
    "\n",
    "# print(\"SVM Classifier Accuracy: \", accuracy_SVM*100, \"%\")\n",
    "print(\"SVM Classifier Accuracy: \", accuracy_SVM2*100, \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy:  86.11111111111111 %\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Classifier Accuracy: \", accuracy_SVM2*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TESTING [With Camera]***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_predictions=[]\n",
    "# k=0\n",
    "# # url = \"http://10.1.0.144:8080/video\"\n",
    "# url = \"http://192.168.58.58:8080/video\"\n",
    "# cap = cv2.VideoCapture(0) # 0--> Webcam  url-->from mobile\n",
    "# emotion_dict_reversed={\n",
    "#         0:\"anger\",\n",
    "#         1:\"disgust\",\n",
    "#         6:\"fear\",\n",
    "#         3:\"happiness\",\n",
    "#         4:\"neutral\",\n",
    "#         5:\"sadness\",\n",
    "#         6:\"surprise\"\n",
    "#     }\n",
    "# read_test=0\n",
    "# while(True):\n",
    "#     camera, frame = cap.read()\n",
    "#     if frame is not None:\n",
    "#         frame=cv2.resize(frame,(500,500))\n",
    "#         test_point,x,y,w=extract_features_test(frame,pca,pcaGabor,viola_inst,-1)\n",
    "#         if(len(test_point)!=0):\n",
    "#             for i in range(test_point.shape[0]):\n",
    "#                 res=clf.predict(test_point[i].reshape(1,-1))\n",
    "#                 res=res[0]\n",
    "#                 print(\"prediction= \",emotion_dict_reversed[res])\n",
    "#                 cv2.rectangle(frame,(x[i],y[i]), (x[i]+w[i],y[i]+w[i]), (255,0,0), thickness=3)\n",
    "#                 cv2.putText(frame, emotion_dict_reversed[res] ,(int(x[i]+w[i]), int(y[i]+w[i])),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "\n",
    "#         cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "#     if cv2.waitKey(10) == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # # When everything is done, release the capture\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing The Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Confusion Matrix: \n",
      "[[15  2  3  0  4]\n",
      " [ 0 22  0  0  0]\n",
      " [ 0  0 13  0  2]\n",
      " [ 1  1  0 23  0]\n",
      " [ 0  0  1  1 20]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_SVM = confusion_matrix(labels_test, svm_predictions)\n",
    "print(\"SVM Confusion Matrix: \")\n",
    "print(confusion_matrix_SVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparision Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pca (708, 90)\n",
      "gabor_pca (708, 270)\n",
      "f= (708, 360)\n",
      "79.8072120667266\n"
     ]
    }
   ],
   "source": [
    "#Kfold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "# clf_cross_validation = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf_cross_validation = SVC(kernel='linear',C=5,gamma=\"scale\")#SVC(gamma='scale',C=1000)\n",
    "# features_dataset=extract_features_training()\n",
    "features_dataset,pca_dataset,pcaGabor_dataset,labels_train_dataset=extract_features_training(images_dataset,labels_dataset,viola_inst)\n",
    "scores = cross_val_score(clf_cross_validation, features_dataset, labels_train_dataset, cv=5)\n",
    "\n",
    "print((np.sum(scores)/5)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.8072120667266\n"
     ]
    }
   ],
   "source": [
    "print((np.sum(scores)/5)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "F1-score on testing data for SVM: 85.7277%\n"
     ]
    }
   ],
   "source": [
    "#F1-score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# labels_test, svm_predictions\n",
    "print(len(svm_predictions))\n",
    "\n",
    "print(\"F1-score on testing data for SVM: {:.4f}%\".format(f1_score(labels_test, np.array(svm_predictions),average='weighted')*100))\n",
    "# print(\"F1-score on testing data for Random Forest: {:.4f}%\".format(f1_score(labels_test, np.array(svm_predictions),average='weighted')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger Precision :  62.5 Recall :  93.75\n",
      "Disgust Precision :  100.0 Recall :  88.0\n",
      "Fear Precision :  86.66666666666667 Recall :  76.47058823529412\n",
      "Happiness Precision :  92.0 Recall :  95.83333333333333\n",
      "Sadness Precision :  90.9090909090909 Recall :  76.92307692307692\n"
     ]
    }
   ],
   "source": [
    "precision =[]\n",
    "recall =[]\n",
    "for i in range(confusion_matrix_SVM.shape[0]):\n",
    "    precision.append(confusion_matrix_SVM[i][i]*100/sum(confusion_matrix_SVM[i]))\n",
    "    recall.append(confusion_matrix_SVM[i][i]*100/np.sum(confusion_matrix_SVM,axis=0)[i])\n",
    "\n",
    "\n",
    "# print(\"Stress Precision : \",precision[0] , \"Recall : \", recall[0])\n",
    "# print(\"Not stress Precision : \",precision[1] , \"Recall : \", recall[1])\n",
    "# print(\"Fear Precision : \",precision[2] , \"Recall : \", recall[2] )\n",
    "# print(\"Happiness Precision : \",precision[3] , \"Recall : \", recall[3] )\n",
    "# print(\"Sadness Precision : \",precision[4] , \"Recall : \", recall[4] )\n",
    "\n",
    "print(\"Anger Precision : \",precision[0] , \"Recall : \", recall[0])\n",
    "print(\"Disgust Precision : \",precision[1] , \"Recall : \", recall[1])\n",
    "print(\"Fear Precision : \",precision[2] , \"Recall : \", recall[2] )\n",
    "print(\"Happiness Precision : \",precision[3] , \"Recall : \", recall[3] )\n",
    "print(\"Sadness Precision : \",precision[4] , \"Recall : \", recall[4] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[15  2  4  0  3]     \n",
    "#  [ 0 22  0  0  0]\n",
    "#  [ 0  0 13  0  2]\n",
    "#  [ 1  0  0 24  0]\n",
    "#  [ 0  0  2  0 20]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a76cc94cdb2ea0e3d4b4b62890ac8be9dbe5f144a88cb508caf3e8ff4445435"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
